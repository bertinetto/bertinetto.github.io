<!-- Projects -->
<hr class="featurette-divider">
<h3><b>Selected publications</b></h3>
<h5>For an up-to-date list, see my <a
        href="https://scholar.google.it/citations?hl=en&user=zEy5CTkAAAAJ&view_op=list_works&sortby=pubdate">Google
        Scholar profile</a>.</h5>
<!--------------------------------->
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
    <tbody>


        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/lame_non_iid_toy.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Parameter-free Online Test-time Adaptation
                </h4>
                <h6 class="text-muted">Malik Boudiaf, Romain Mueller, Ismail Ben Ayed, <u>Luca Bertinetto</u></h6>
                CVPR 2022 (oral)
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/2201.05718">Paper</a> /
                    <a href="https://github.com/fiveai/LAME">Code</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/iclr2022_loss_landscape.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Attacking deep networks with surrogate-based adversarial black-box methods is easy
                </h4>
                <h6 class="text-muted">Nicholas A. Lord, Romain Mueller, <u>Luca Bertinetto</u></h6>
                ICLR 2022
                <br><br>
                <p class="lead">
                    <a href="https://openreview.net/forum?id=Zf4ZdI4OQPV">Paper</a> /
                    <a href="https://github.com/fiveai/GFCS">Code</a> /
                    <a href="https://www.youtube.com/watch?v=gKzwEq6j5C8&ab_channel=NicholasLord">Video</a> /
                    <a
                        href="https://medium.com/fiveai/many-deep-nets-are-more-similar-than-you-might-think-34e9bc3c6a2e">Blogpost</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>

        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/neurips2021_unitrack_radar10.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Do Different Tracking Tasks Require Different Appearance Models?
                </h4>
                <h6 class="text-muted">Zhongdao Wang, Hengshuang Zhao, Ya-Li Li, Shengjin Wang, Philip H.S. Torr,
                    <u>Luca
                        Bertinetto</u></h6>
                NeurIPS 2021
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/2107.02156">Paper</a> /
                    <a href="https://github.com/Zhongdao/UniTrack">Code</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>


        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/neurips2021_episodes.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    On Episodes, Prototypical Networks, and Few-Shot Learning
                </h4>
                <h6 class="text-muted">Steinar Laenen, <u>Luca Bertinetto</u></h6>
                NeurIPS 2021
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/2012.09831">Paper</a> /
                    <a href="https://github.com/fiveai/on-episodes-fsl">Code</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>


        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="https://raw.githubusercontent.com/fiveai/making-better-mistakes/master/assets/figures_history.png"
                        width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Making Better Mistakes: Leveraging Class Hierarchies with Deep Networks
                </h4>
                <h6 class="text-muted"><u>Luca Bertinetto *</u>, Romain Mueller *, Konstantinos Tertikas, Sina
                    Samangooei,
                    Nicholas A. Lord *</h6>
                CVPR 2020
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/1912.09393">Paper</a> /
                    <a href="https://github.com/fiveai/making-better-mistakes">Code</a> /
                    <a href="https://www.youtube.com/watch?v=SIHI8458Fkk">Short video</a> /
                    <a href="research_pdf/cvpr2020_slides.pdf">Slides</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>

        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/r2d2_pipeline.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Meta-learning with Differentiable Closed-form Solvers
                </h4>
                <h6 class="text-muted"><u>Luca Bertinetto</u>, João Henriques, Philip Torr, Andrea Vedaldi</h6>
                ICLR 2019
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/1805.08136">Paper</a> /
                    <a href="https://github.com/bertinetto/r2d2">Code</a> /
                    <a href="research_pages/pdf/poster_iclr19.pdf">Poster</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="https://camo.githubusercontent.com/56e5addf0cbc6f75088a41996d5a7da2231c541a/687474703a2f2f7777772e726f626f74732e6f782e61632e756b2f7e7177616e672f5369616d4d61736b2f696d672f5369616d4d61736b5f64656d6f2e676966"
                        width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Fast Online Object Tracking and Segmentation: A Unifying Approach
                </h4>
                <h6 class="text-muted">Qiang Wang *, Li Zhang *, <u>Luca Bertinetto *</u>, Weiming Hu, Philip Torr</h6>
                CVPR 2019 / TPAMI 2022
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/1812.05050">Paper</a> /
                    <a href="https://arxiv.org/abs/2207.02088">Journal version</a> /
                    <!-- <a href="https://www.robots.ox.ac.uk/~qwang/SiamMask/">Project page</a> / -->
                    <a href="https://github.com/foolwood/SiamMask">Code</a>
                    <!-- <a href="http://www.robots.ox.ac.uk/~qwang/SiamMask/SiamMask_short.mp4">Video</a> -->
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/3dv2019_thumbnail.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Let's Take This Online: Adapting Scene Coordinate Regression Network Predictions for Online RGB-D
                    Camera
                    Relocalisation
                </h4>
                <h6 class="text-muted">Tommaso Cavallari *, <u>Luca Bertinetto</u>, Jishnu Mukhoti, Philip Torr, Stuart
                    Golodetz *</h6>
                3DV 2019 (oral)
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/1906.08744">Paper</a> /
                    <a href="https://github.com/torrvision/spaint">Code</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/thesis_thumbnail.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Learning (to Learn) from Few Examples
                </h4>
                <!-- <h5>Visual Tracking and Classification with Limited Data</h5> -->
                <h6 class="text-muted"><u>Luca Bertinetto</u></h6>
                PhD (DPhil) thesis - University of Oxford
                <br><br>
                <p class="lead">
                    <a href="https://ora.ox.ac.uk/objects/uuid:1f93b8a0-9a51-428b-9214-ce563161085a">View on Oxford
                        Research
                        Archive</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/iccv2019_thumbnail.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Anchor Diffusion for Unsupervised Video Object Segmentation
                </h4>
                <h6 class="text-muted">Zhao Yang *, Qiang Wang *, <u>Luca Bertinetto</u>, Weiming Hu, Song Bai, Philip
                    Torr
                </h6>
                ICCV 2019
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/1910.10895">Paper</a> /
                    <a href="https://github.com/yz93/anchor-diff-VOS/">Code</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/eccv2018_thumbnail.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Long-term Tracking in the Wild: A Benchmark
                </h4>
                <h6 class="text-muted">Jack Valmadre *, <u>Luca Bertinetto *</u>, João Henriques, Ran Tao, Andrea
                    Vedaldi,
                    Arnold Smeulders, Philip Torr, Efstratios Gavves *</h6>
                ECCV 2018
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/1803.09502">Paper</a> /
                    <a href="https://oxuva.github.io/long-term-tracking-benchmark/">Project page</a> /
                    <a href="https://github.com/oxuva/long-term-tracking-benchmark">Code</a> /
                    <a
                        href="https://docs.google.com/forms/d/e/1FAIpQLSepA_sLCMrqnZXBPnZFNmggf-MdEGa2Um-Q7pRGQt4SxvGNeg/viewform">Download
                        dataset</a> /
                    <a href="https://competitions.codalab.org/competitions/19529">Competition on CodaLab</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/cvpr2017_thumbnail.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    End-to-end Representation Learning for the Correlation Filter
                </h4>
                <h6 class="text-muted">Jack Valmadre *, <u>Luca Bertinetto *</u>, João Henriques, Andrea Vedaldi, Philip
                    Torr</h6>
                CVPR 2017
                <br><br>
                <p class="lead">
                    <a
                        href="http://openaccess.thecvf.com/content_cvpr_2017/html/Valmadre_End-To-End_Representation_Learning_CVPR_2017_paper.html">Paper</a>
                    /
                    <a href="research_pages/cfnet.html">Project page</a> /
                    <a href="https://github.com/bertinetto/cfnet">Code</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/neurips2016_thumbnail.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Learning Feed-forward One-shot Learners
                </h4>
                <h6 class="text-muted"><u>Luca Bertinetto *</u>, João Henriques *, Jack Valmadre *, Philip Torr, Andrea
                    Vedaldi</h6>
                NeurIPS 2016
                <br><br>
                <p class="lead">
                    <a href="https://papers.nips.cc/paper/6068-learning-feed-forward-one-shot-learners">Paper</a> /
                    <a href="https://youtu.be/BnLN3uoXMRY">Seminar video</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/siamesefc_conv-explicit.jpg" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Fully-Convolutional Siamese Networks for Object Tracking
                </h4>
                <h6 class="text-muted"><u>Luca Bertinetto *</u> , Jack Valmadre *, João Henriques, Andrea Vedaldi,
                    Philip
                    Torr</h6>
                ECCV 2016 - VOT workshop
                <br><br>
                <p class="lead">
                    <a href="https://arxiv.org/abs/1606.09549">Paper</a> /
                    <a href="research_pages/siamese-fc.html">Project page</a> /
                    <a href="https://github.com/bertinetto/siamese-fc">Code</a> /
                    <a href="https://www.youtube.com/watch?v=jZoUalMMZ_0">Seminar video (RE·WORK)</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
                <div>
                    <img src="research_pages/thumbnails/pipeline_horizontal.png" width="320">
                </div>
            </td>
            <td style="padding:20px;width:75%;vertical-align:middle">
                <h4>
                    Staple: Complementary Learners for Real-Time Tracking
                </h4>
                <h6 class="text-muted"><u>Luca Bertinetto</u>, Jack Valmadre, Stuart Golodetz, Ondrej Miksik, Philip
                    Torr
                </h6>
                CVPR 2016
                <br><br>
                <p class="lead">
                    <a
                        href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/html/Bertinetto_Staple_Complementary_Learners_CVPR_2016_paper.html">Paper</a>
                    /
                    <a href="research_pages/staple.html">Project page</a> /
                    <a href="https://github.com/bertinetto/staple">Code</a> /
                    <a href="research_pdf/poster_staple.pdf">Poster (pdf)</a> /
                    <a href="research_pdf/report_oacf.pdf">Report on preliminary version (OACF)</a>
                </p>
                <p></p>
                <p> </p>
            </td>
        </tr>
        <!--------------------------------->
    </tbody>
</table>